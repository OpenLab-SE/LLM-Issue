{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "011a2e2a-0505-4cd0-af48-6ec3787aff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbdc070-7e96-4959-a409-66f573352ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('./my_data/train/deepfacelab.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1931c4ba-e7f6-4f69-9721-534c3b738d84",
   "metadata": {},
   "source": [
    "### Add Length of title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec2e64-1c1d-41d0-91ed-f238b38549f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>number</th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iperov/DeepFaceLab</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/iperov/DeepFaceLab/issues/1</td>\n",
       "      <td>`Error: Sorry, this model works only on 2GB+ G...</td>\n",
       "      <td>## Expected behavior_x000D_\\nStart training._x...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fullname  number                                        html_url  \\\n",
       "0  iperov/DeepFaceLab       1  https://github.com/iperov/DeepFaceLab/issues/1   \n",
       "\n",
       "                                               title  \\\n",
       "0  `Error: Sorry, this model works only on 2GB+ G...   \n",
       "\n",
       "                                         description labels  \n",
       "0  ## Expected behavior_x000D_\\nStart training._x...  other  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd77ed3-cf6e-4bc5-8d48-6bd0ef54841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _strlen(sentence):\n",
    "    import re\n",
    "    zhmodel = re.compile(u'[\\u4e00-\\u9fa5]')  # 检查中文\n",
    "    contents = str(sentence)\n",
    "    match = zhmodel.search(contents)\n",
    "    if match:\n",
    "        return -1\n",
    "    else:\n",
    "        return len(str(sentence).strip().split(' '))\n",
    "\n",
    "title_lens, body_lens = df['title'].apply(_strlen), df['description'].apply(_strlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f3701f-47f5-4e4a-bc8a-6860f21ee60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "df.insert(loc=df.columns.get_loc(\"title\") + 1, column='title_lens', value=title_lens)\n",
    "df.insert(loc=df.columns.get_loc(\"description\") + 1, column='description_lens', value=body_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c02665-4b6d-458a-bffc-2ee713917eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>number</th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>title_lens</th>\n",
       "      <th>description</th>\n",
       "      <th>description_lens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iperov/DeepFaceLab</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/iperov/DeepFaceLab/issues/1</td>\n",
       "      <td>`Error: Sorry, this model works only on 2GB+ G...</td>\n",
       "      <td>15</td>\n",
       "      <td>## Expected behavior_x000D_\\nStart training._x...</td>\n",
       "      <td>375</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fullname  number                                        html_url  \\\n",
       "0  iperov/DeepFaceLab       1  https://github.com/iperov/DeepFaceLab/issues/1   \n",
       "\n",
       "                                               title  title_lens  \\\n",
       "0  `Error: Sorry, this model works only on 2GB+ G...          15   \n",
       "\n",
       "                                         description  description_lens labels  \n",
       "0  ## Expected behavior_x000D_\\nStart training._x...               375  other  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f778f-3d1a-43d8-80de-43fd06e0ce55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7815b19-f479-48d0-ae11-25be9db92434",
   "metadata": {},
   "source": [
    "### Remove nan Label and short title with no description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3872e9c-7526-4fee-b010-05c04b4433bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'Low efficiency and Effectiveness', 'deployment', 'Error',\n",
       "       'tensor&inputs'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e5d64-aa13-465e-be54-591ea2cc96fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>number</th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>title_lens</th>\n",
       "      <th>description</th>\n",
       "      <th>description_lens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fullname, number, html_url, title, title_lens, description, description_lens, labels]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contain_na = df[df['labels'].isnull()]\n",
    "contain_na.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede29a6-0509-497b-8489-dd8d582a8959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:716, after:716\n"
     ]
    }
   ],
   "source": [
    "len_before = len(df)\n",
    "df.dropna(subset = ['labels'], inplace=True)\n",
    "len_after = len(df)\n",
    "print(f'before:{len_before}, after:{len_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea49335a-5cbe-4ca4-ad85-795173434792",
   "metadata": {},
   "outputs": [],
   "source": [
    "contain_chinese_characters = df[((df.title_lens == -1) & (df.description_lens == -1))]\n",
    "df = df.drop(contain_chinese_characters.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dcd06b-399a-4bf8-950e-7f7a16e2cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_nan = df[((df.title_lens == 1) & (df.description.isnull()))]\n",
    "df = df.drop(body_nan.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d14652-cccc-4e3c-9d75-02b6d1f4b020",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbdaa67-0e94-4ad9-ae16-378dfea2f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['title_lens', 'description_lens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3defdda-051a-4621-bd61-b0b064d223bd",
   "metadata": {},
   "source": [
    "# save the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1fdec7-2b0e-42c7-9197-3e1f09afa907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iperov_DeepFaceLab'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = '_'.join(df['fullname'][0].split('/'))\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64405daa-72d7-4e55-859d-ba4cf16ceafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join('./my_data', name)):\n",
    "    os.mkdir(os.path.join('./my_data', name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc6266-18b5-4390-b103-6d0c8caf480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(f'{name}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d975e0-a355-4b3a-af2d-ee7bd09790f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "result = df[['title', 'description', 'labels']].to_json(orient=\"records\")\n",
    "parsed = json.loads(result)\n",
    "\n",
    "with open(f'{name}.txt', 'w') as f:\n",
    "    json.dump(parsed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861269d-d29c-4ce1-942b-e7280cd59989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'setUpfailed', 'description': '![default](https://user-images.githubusercontent.com/28338863/53715027-7e309480-3e8b-11e9-8d5b-aebb44e63f9e.png)\\r\\n\\r\\ndear editor,what does these mean?', 'labels': 'other'}\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open('deepfakes_faceswap.txt', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for obj in data:\n",
    "    print(obj)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86894a34-5dd3-4553-a2e4-895b3163d061",
   "metadata": {},
   "source": [
    "## 组合label文件和comments文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95766f52-c15c-40fc-a9e7-8f2f17c2250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取Excel文件\n",
    "df1 = pd.read_excel('./issue_data/issue_xlxs/EasyOCR_issue_classify_2024_01_01.xlsx')  # 包含comment_concat_str列\n",
    "df2 = pd.read_excel('./issue_data/issue_newlabel/EasyOCR_newlabel.xlsx')  # 要把数据合并到这个文件\n",
    "\n",
    "# 基于'number'列进行合并，使用left join以保留df2中所有行\n",
    "merged_df = pd.merge(df2, df1[['number', 'commment_concat_str']], on='number', how='left')\n",
    "\n",
    "# 把合并后的DataFrame保存为新的Excel文件, 如果想要替换file2.xlsx，直接覆盖即可\n",
    "merged_df.to_excel('./issue_data/issue_newlabel_comments/EasyOCR_newlabel_with_comments.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd6cbf-0e24-4b5c-9a17-c3959414d52d",
   "metadata": {},
   "source": [
    "## Combine the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f491ada-a48c-4f2f-878c-5717be875f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defff7f8-1883-4ca2-95e6-1f7db4ee3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _strlen(sentence):\n",
    "    import re\n",
    "    zhmodel = re.compile(u'[\\u4e00-\\u9fa5]')  #检查中文\n",
    "    contents = str(sentence)\n",
    "    match = zhmodel.search(contents)\n",
    "    if match:\n",
    "        return -1\n",
    "    else:\n",
    "        return len(str(sentence).strip().split(' '))\n",
    "\n",
    "def concatenate_df_and_save(dfs):\n",
    "    df = pd.concat(dfs)\n",
    "    dir_name = os.path.join('./my_data/train', 'concat')\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    \n",
    "    out_path = os.path.join(dir_name, 'concat.txt')\n",
    "    result = df[['title', 'description', 'labels']].to_json(orient=\"records\")\n",
    "    parsed = json.loads(result)\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(parsed, f)\n",
    "\n",
    "def save_df(df, filename, stage=\"train\"):\n",
    "    if stage == \"train\":\n",
    "        dir_name = os.path.join('./my_data/train', filename)\n",
    "    elif stage == \"test\":\n",
    "        dir_name = os.path.join('./my_data/test', filename)\n",
    "    elif stage == \"valid\":\n",
    "        dir_name = os.path.join('./my_data/valid', filename)\n",
    "\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    \n",
    "    out_path = os.path.join(dir_name, filename + '.txt')\n",
    "    if 'commment_concat_str' in df.columns:\n",
    "        # result = df[['title', 'description', 'commment_concat_str', 'labels']].to_json(orient=\"records\")\n",
    "        result = df[['number', 'html_url', 'title', 'description', 'commment_concat_str', 'labels']].to_json(orient=\"records\")\n",
    "    else:\n",
    "        result = df[['number', 'html_url', 'title', 'description', 'labels']].to_json(orient=\"records\")\n",
    "    parsed = json.loads(result)\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(parsed, f)\n",
    "    \n",
    "def preprocess(file):\n",
    "    df = pd.read_excel(file)\n",
    "    # add title and description length\n",
    "    title_lens, description_lens = df['title'].apply(_strlen), df['description'].apply(_strlen)\n",
    "\n",
    "    df.insert(loc=df.columns.get_loc(\"title\") + 1, column='title_lens', value=title_lens)\n",
    "    df.insert(loc=df.columns.get_loc(\"description\") + 1, column='description_lens', value=description_lens)\n",
    "    \n",
    "    name = '_'.join(df['fullname'][0].split('/'))\n",
    "    print(f'before drop, the length of {name} is:{len(df)}')\n",
    "    \n",
    "    # drop the nan\n",
    "    df.dropna(subset = ['title', 'description', 'labels'], inplace=True)\n",
    "    \n",
    "    # drop the chinese issues\n",
    "    contain_chinese_characters = df[((df.title_lens == -1) & (df.description_lens == -1))]\n",
    "    df.drop(contain_chinese_characters.index, inplace=True)\n",
    "    \n",
    "    print(f'after drop, the length of {name} is:{len(df)}')\n",
    "\n",
    "    # whether or not to convert erery xlxs file to json file\n",
    "    \n",
    "    # name = '_'.join(df['fullname'][0].split('/'))\n",
    "    # dir_name = os.path.join('./my_data', name)\n",
    "    # if not os.path.exists(dir_name):\n",
    "    #     os.mkdir(dir_name)\n",
    "    \n",
    "    # out_path = os.path.join(dir_name, f'{name}.txt')\n",
    "    # result = df[['title', 'description', 'labels']].to_json(orient=\"records\")\n",
    "    # parsed = json.loads(result)\n",
    "\n",
    "    # with open(out_path, 'w') as f:\n",
    "    #     json.dump(parsed, f)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def preprocess_vote(file, group_num=3):\n",
    "    df = pd.read_excel(file)\n",
    "    # add title and description length\n",
    "    title_lens, description_lens = df['title'].apply(_strlen), df['description'].apply(_strlen)\n",
    "\n",
    "    df.insert(loc=df.columns.get_loc(\"title\") + 1, column='title_lens', value=title_lens)\n",
    "    df.insert(loc=df.columns.get_loc(\"description\") + 1, column='description_lens', value=description_lens)\n",
    "    \n",
    "    name = '_'.join(df['fullname'][0].split('/'))\n",
    "    print(f'before drop, the length of {name} is:{len(df)}')\n",
    "\n",
    "    # 标记需要删除的行\n",
    "    rows_to_drop = set()\n",
    "    for i in range(0, len(df), group_num):\n",
    "        group = df.iloc[i:i+group_num]\n",
    "        print(group)\n",
    "        print(f'row {i} group.isnull().any(axis=1).any() is {group.isnull().any(axis=1).any()}')\n",
    "        if group.isnull().any(axis=1).any() or ((group['title_lens'] == -1) & (group['description_lens'] == -1)).any():\n",
    "            rows_to_drop.update(group.index)\n",
    "\n",
    "    # 删除标记的行\n",
    "    df.drop(rows_to_drop, inplace=True)\n",
    "    \n",
    "    print(f'after drop, the length of {name} is:{len(df)}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70292c59",
   "metadata": {},
   "source": [
    "### Concat train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b097de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "# dfs.append(preprocess('my_data/train/pytorch-CycleGAN-and-pix2pix_TRAIN_Aug.xlsx'))\n",
    "# dfs.append(preprocess('my_data/train/Real-Time-Voice-Cloning_TRAIN_Aug.xlsx'))\n",
    "# dfs.append(preprocess('my_data/train/EasyOCR_TRAIN_Aug.xlsx'))\n",
    "# dfs.append(preprocess('my_data/train/recommenders1_TRAIN_Aug.xlsx')) \n",
    "# # dfs.append(preprocess('my_data/train/streamlit1_TRAIN_Aug.xlsx'))\n",
    "# concatenate_df_and_save(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8474d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop, the length of CMU-Perceptual-Computing-Lab_openpose is:8680\n",
      "after drop, the length of CMU-Perceptual-Computing-Lab_openpose is:8666\n",
      "before drop, the length of CMU-Perceptual-Computing-Lab_openpose is:656\n",
      "after drop, the length of CMU-Perceptual-Computing-Lab_openpose is:653\n",
      "before drop, the length of dusty-nv_jetson-inference is:1094\n",
      "after drop, the length of dusty-nv_jetson-inference is:1090\n"
     ]
    }
   ],
   "source": [
    "save_df(preprocess('my_data/train/caffe_pytorch_newlabel_clean_TRAIN_Aug.xlsx'), 'caffe_pytorch_newlabel_clean_TRAIN_Aug')\n",
    "save_df(preprocess('my_data/valid/caffe_pytorch_newlabel_clean_VALID_Aug.xlsx'), 'caffe_pytorch_newlabel_clean_VALID_Aug', \"valid\")\n",
    "save_df(preprocess('my_data/test/caffe_pytorch_newlabel_clean_TEST_Aug.xlsx'), 'caffe_pytorch_newlabel_clean_TEST_Aug', \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b612303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop, the length of deezer_spleeter is:14445\n",
      "after drop, the length of deezer_spleeter is:14428\n",
      "before drop, the length of streamlit_streamlit is:1328\n",
      "after drop, the length of streamlit_streamlit is:1325\n",
      "before drop, the length of streamlit_streamlit is:1934\n",
      "after drop, the length of streamlit_streamlit is:1929\n"
     ]
    }
   ],
   "source": [
    "save_df(preprocess('my_data/train/framework_newlabel_clean_TRAIN_Aug.xlsx'), 'framework_newlabel_clean_TRAIN_Aug')\n",
    "save_df(preprocess('my_data/valid/framework_newlabel_clean_VALID_Aug.xlsx'), 'framework_newlabel_clean_VALID_Aug', \"valid\")\n",
    "save_df(preprocess('my_data/test/framework_newlabel_clean_TEST_Aug.xlsx'), 'framework_newlabel_clean_TEST_Aug', \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4e5486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop, the length of JaidedAI_EasyOCR is:4545\n",
      "after drop, the length of JaidedAI_EasyOCR is:4536\n",
      "before drop, the length of CorentinJ_Real-Time-Voice-Cloning is:329\n",
      "after drop, the length of CorentinJ_Real-Time-Voice-Cloning is:326\n",
      "before drop, the length of junyanz_pytorch-CycleGAN-and-pix2pix is:549\n",
      "after drop, the length of junyanz_pytorch-CycleGAN-and-pix2pix is:545\n",
      "before drop, the length of deezer_spleeter is:5765\n",
      "after drop, the length of deezer_spleeter is:5762\n",
      "before drop, the length of streamlit_streamlit is:672\n",
      "after drop, the length of streamlit_streamlit is:672\n",
      "before drop, the length of streamlit_streamlit is:840\n",
      "after drop, the length of streamlit_streamlit is:839\n",
      "before drop, the length of CMU-Perceptual-Computing-Lab_openpose is:4135\n",
      "after drop, the length of CMU-Perceptual-Computing-Lab_openpose is:4135\n",
      "before drop, the length of CMU-Perceptual-Computing-Lab_openpose is:327\n",
      "after drop, the length of CMU-Perceptual-Computing-Lab_openpose is:326\n",
      "before drop, the length of dusty-nv_jetson-inference is:545\n",
      "after drop, the length of dusty-nv_jetson-inference is:545\n"
     ]
    }
   ],
   "source": [
    "# save_df(preprocess('my_data/train/pytorch-CycleGAN-and-pix2pix_TRAIN_Aug.xlsx'), 'pytorch-CycleGAN-and-pix2pix_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/train/Real-Time-Voice-Cloning_TRAIN_Aug.xlsx'), 'Real-Time-Voice-Cloning_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/train/EasyOCR_TRAIN_Aug.xlsx'), 'EasyOCR_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/train/recommenders1_TRAIN_Aug.xlsx'), 'recommenders1_TRAIN_Aug') \n",
    "# save_df(preprocess('my_data/train/streamlit1_TRAIN_Aug.xlsx'), 'streamlit1_TRAIN_Aug')\n",
    "\n",
    "# save_df(preprocess('my_data/train/streamlit_clean_TRAIN_Aug.xlsx'), 'streamlit_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/streamlit_clean_TEST_Aug.xlsx'), 'streamlit_clean_TEST_Aug', False)\n",
    "\n",
    "# streamlit newlabel\n",
    "# save_df(preprocess('my_data/train/streamlit_new_clean_TRAIN_Aug.xlsx'), 'streamlit_new_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/valid/streamlit_new_clean_VALID_Aug.xlsx'), 'streamlit_new_clean_VALID_Aug', \"valid\")\n",
    "# save_df(preprocess('my_data/test/streamlit_new_clean_TEST_Aug.xlsx'), 'streamlit_new_clean_TEST_Aug', \"test\")\n",
    "\n",
    "#  newlabel Real-Time-Voice-Cloning_newlabel_clean_TRAIN_Aug\n",
    "save_df(preprocess('my_data/train/pytorch_newlabel_clean_TRAIN_Aug.xlsx'), 'pytorch_newlabel_clean_TRAIN_Aug')\n",
    "save_df(preprocess('my_data/valid/pytorch_newlabel_clean_VALID_Aug.xlsx'), 'pytorch_newlabel_clean_VALID_Aug', \"valid\")\n",
    "save_df(preprocess('my_data/test/pytorch_newlabel_clean_TEST_Aug.xlsx'), 'pytorch_newlabel_clean_TEST_Aug', \"test\")\n",
    "\n",
    "save_df(preprocess('my_data/train/tensorflow_newlabel_clean_TRAIN_Aug.xlsx'), 'tensorflow_newlabel_clean_TRAIN_Aug')\n",
    "save_df(preprocess('my_data/valid/tensorflow_newlabel_clean_VALID_Aug.xlsx'), 'tensorflow_newlabel_clean_VALID_Aug', \"valid\")\n",
    "save_df(preprocess('my_data/test/tensorflow_newlabel_clean_TEST_Aug.xlsx'), 'tensorflow_newlabel_clean_TEST_Aug', \"test\")\n",
    "\n",
    "save_df(preprocess('my_data/train/caffe_newlabel_clean_TRAIN_Aug.xlsx'), 'caffe_newlabel_clean_TRAIN_Aug')\n",
    "save_df(preprocess('my_data/valid/caffe_newlabel_clean_VALID_Aug.xlsx'), 'caffe_newlabel_clean_VALID_Aug', \"valid\")\n",
    "save_df(preprocess('my_data/test/caffe_newlabel_clean_TEST_Aug.xlsx'), 'caffe_newlabel_clean_TEST_Aug', \"test\")\n",
    "\n",
    "\n",
    "# save_df(preprocess('my_data/train/Real-Time-Voice-Cloning_newlabel_clean_TRAIN_Aug.xlsx'), 'Real-Time-Voice-Cloning_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/valid/Real-Time-Voice-Cloning_newlabel_clean_VALID_Aug.xlsx'), 'Real-Time-Voice-Cloning_newlabel_clean_VALID_Aug', \"valid\")\n",
    "# save_df(preprocess('my_data/test/Real-Time-Voice-Cloning_newlabel_clean_TEST_Aug.xlsx'), 'Real-Time-Voice-Cloning_newlabel_clean_TEST_Aug', \"test\")\n",
    "\n",
    "# save_df(preprocess('my_data/train/openpose_newlabel_clean_TRAIN_Aug.xlsx'), 'openpose_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/valid/openpose_newlabel_clean_VALID_Aug.xlsx'), 'openpose_newlabel_clean_VALID_Aug', \"valid\")\n",
    "# save_df(preprocess('my_data/test/openpose_newlabel_clean_TEST_Aug.xlsx'), 'openpose_newlabel_clean_TEST_Aug', \"test\")\n",
    "\n",
    "# save_df(preprocess('my_data/train/pytorch-CycleGAN-and-pix2pix_newlabel_clean_TRAIN_Aug.xlsx'), 'pytorch-CycleGAN-and-pix2pix_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/valid/pytorch-CycleGAN-and-pix2pix_newlabel_clean_VALID_Aug.xlsx'), 'pytorch-CycleGAN-and-pix2pix_newlabel_clean_VALID_Aug', \"valid\")\n",
    "# save_df(preprocess('my_data/test/pytorch-CycleGAN-and-pix2pix_newlabel_clean_TEST_Aug.xlsx'), 'pytorch-CycleGAN-and-pix2pix_newlabel_clean_TEST_Aug', \"test\")\n",
    "\n",
    "# save_df(preprocess('my_data/train/deepfacelab_newlabel_clean_TRAIN_Aug.xlsx'), 'deepfacelab_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/valid/deepfacelab_newlabel_clean_VALID_Aug.xlsx'), 'deepfacelab_newlabel_clean_VALID_Aug', \"valid\")\n",
    "# save_df(preprocess('my_data/test/deepfacelab_newlabel_clean_TEST_Aug.xlsx'), 'deepfacelab_newlabel_clean_TEST_Aug', \"test\")\n",
    "\n",
    "# save_df(preprocess('my_data/train/faceswap_newlabel_clean_TRAIN_Aug.xlsx'), 'faceswap_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/valid/faceswap_newlabel_clean_VALID_Aug.xlsx'), 'faceswap_newlabel_clean_VALID_Aug', \"valid\")\n",
    "# save_df(preprocess('my_data/test/faceswap_newlabel_clean_TEST_Aug.xlsx'), 'faceswap_newlabel_clean_TEST_Aug', \"test\")\n",
    "\n",
    "# save_df(preprocess('my_data/train/faceswap_newlabel_clean_TRAIN_Aug.xlsx'), 'faceswap_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/faceswap_newlabel_clean_TEST_Aug.xlsx'), 'faceswap_newlabel_clean_TEST_Aug', False)\n",
    "\n",
    "# save_df(preprocess('my_data/train/EasyOCR_newlabel_clean_TRAIN_Aug.xlsx'), 'EasyOCR_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/valid/EasyOCR_newlabel_clean_VALID_Aug.xlsx'), 'EasyOCR_newlabel_clean_VALID_Aug', \"valid\")\n",
    "# save_df(preprocess('my_data/test/EasyOCR_newlabel_clean_TEST_Aug.xlsx'), 'EasyOCR_newlabel_clean_TEST_Aug', \"test\")\n",
    "\n",
    "# save_df(preprocess('my_data/train/EasyOCR_newlabel_with_comments_clean_TRAIN_Aug.xlsx'), 'EasyOCR_newlabel_with_comments_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/valid/EasyOCR_newlabel_with_comments_clean_VALID_Aug.xlsx'), 'EasyOCR_newlabel_with_comments_clean_VALID_Aug', \"valid\")\n",
    "# save_df(preprocess('my_data/test/EasyOCR_newlabel_with_comments_clean_TEST_Aug.xlsx'), 'EasyOCR_newlabel_with_comments_clean_TEST_Aug', \"test\")\n",
    "\n",
    "# save_df(preprocess('my_data/train/EasyOCR_newlabel_clean_TRAIN_Aug.xlsx'), 'EasyOCR_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/valid/EasyOCR_newlabel_clean_VALID_Aug.xlsx'), 'EasyOCR_newlabel_clean_VALID_Aug', \"valid\")\n",
    "# save_df(preprocess('my_data/test/EasyOCR_newlabel_clean_TEST_Aug.xlsx'), 'EasyOCR_newlabel_clean_TEST_Aug', \"test\")\n",
    "\n",
    "# save_df(preprocess('my_data/train/deepfacelab_newlabel_clean_TRAIN_Aug.xlsx'), 'deepfacelab_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/deepfacelab_newlabel_clean_TEST_Aug.xlsx'), 'deepfacelab_newlabel_clean_TEST_Aug', False)\n",
    "\n",
    "# save_df(preprocess('my_data/train/Real-Time-Voice-Cloning_newlabel_clean_TRAIN_Aug.xlsx'), 'Real-Time-Voice-Cloning_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/Real-Time-Voice-Cloning_newlabel_clean_TEST_Aug.xlsx'), 'Real-Time-Voice-Cloning_newlabel_clean_TEST_Aug', False)\n",
    "\n",
    "# save_df(preprocess('my_data/train/recommenders_newlabel_TRAIN_Aug.xlsx'), 'recommenders_newlabel_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/recommenders_newlabel_clean_TEST_Aug.xlsx'), 'recommenders_newlabel_clean_TEST_Aug', False)\n",
    "\n",
    "# save_df(preprocess('my_data/train/TTS_newlabel_clean_TRAIN_Aug.xlsx'), 'TTS_newlabel_clean_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/TTS_newlabel_clean_TEST_Aug.xlsx'), 'TTS_newlabel_clean_TEST_Aug', False)\n",
    "\n",
    "\n",
    "\n",
    "# save_df(preprocess_vote('my_data/test/streamlit_new_clean_TEST_AugVote2.xlsx'), 'streamlit_new_clean_TEST_AugVote2', False)\n",
    "\n",
    "# save_df(preprocess('my_data/train/streamlit_clean_1_TRAIN_Aug.xlsx'), 'streamlit_clean_1_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/streamlit_clean_1_TEST_Aug.xlsx'), 'streamlit_clean_1_TEST_Aug', False)\n",
    "\n",
    "# save_df(preprocess('my_data/train/faceswap_TRAIN_Aug.xlsx'), 'faceswap_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/faceswap_TEST_Aug.xlsx'), 'faceswap_TEST_Aug', False)\n",
    "\n",
    "# save_df(preprocess('my_data/train/deepfacelab_TRAIN_Aug.xlsx'), 'deepfacelab_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/deepfacelab_TEST_Aug.xlsx'), 'deepfacelab_TEST_Aug', False)\n",
    "\n",
    "# save_df(preprocess('my_data/train/streamlit_TRAIN_Aug.xlsx'), 'streamlit_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/streamlit_TEST_Aug.xlsx'), 'streamlit_TEST_Aug', False)\n",
    "# save_df(preprocess_vote('my_data/test/streamlit_TEST_Aug.xlsx'), 'streamlit_TEST_Aug', False)\n",
    "\n",
    "# save_df(preprocess('my_data/train/streamlit_newlabel_TRAIN_Aug.xlsx'), 'streamlit_newlabel_TRAIN_Aug')\n",
    "# save_df(preprocess('my_data/test/streamlit_newlabel_TEST_Aug.xlsx'), 'streamlit_newlabel_TEST_Aug', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff039e1-e625-4ea9-bcc8-123ee581d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob('./my_data/train/*.xlsx')\n",
    "# for f in files:\n",
    "#     print(f)\n",
    "\n",
    "# dfs = []\n",
    "# for f in files:\n",
    "#     dfs.append(preprocess(f))\n",
    "# concatenate_df_and_save(dfs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d611377",
   "metadata": {},
   "source": [
    "## process one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b8a12-cf35-4f51-b19d-1bb227b48aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop, the length of mozilla_TTS is:506\n",
      "after drop, the length of mozilla_TTS is:478\n"
     ]
    }
   ],
   "source": [
    "test_file = './my_data/test/TTS.xlsx'\n",
    "def save_test_to_txt(file):\n",
    "    df = preprocess(file)\n",
    "    file_name = file.split('/')[-1].split('.')[0]\n",
    "    dir_name = os.path.join('./my_data/test', file_name)\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    \n",
    "    out_path = os.path.join(dir_name, f'{file_name}.txt')\n",
    "    result = df[['title', 'description', 'labels']].to_json(orient=\"records\")\n",
    "    parsed = json.loads(result)\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(parsed, f)\n",
    "\n",
    "save_test_to_txt(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7bb83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31561f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc42da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "issue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "c520c937fa0229155174b690de588d25c33cbfee0f5b82be1870097f0ee1af71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
