{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9111102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://nbproxy.mlp.oppo.local:8888'\n",
    "os.environ['https_proxy'] = 'http://nbproxy.mlp.oppo.local:8888'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del os.environ['http_proxy']   #用完需要del代理，否则训练的所有流量都走代理访问，有安全风险\n",
    "del os.environ['https_proxy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5298af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70bbbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo(path):\n",
    "    df = pd.read_excel(path)\n",
    "    return df[[\"full_name\", \"created_at\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c893e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensorflow/tensorflow</td>\n",
       "      <td>2015-11-07T01:19:20Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2012-07-19T09:40:17Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>keras-team/keras</td>\n",
       "      <td>2015-03-28T00:35:42Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pytorch/pytorch</td>\n",
       "      <td>2016-08-13T05:26:41Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scutan90/DeepLearning-500-questions</td>\n",
       "      <td>2018-06-27T06:36:45Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>sepandhaghighi/pycm</td>\n",
       "      <td>2018-01-22T19:46:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>isl-org/MiDaS</td>\n",
       "      <td>2019-06-24T14:08:35Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>abdulfatir/twitter-sentiment-analysis</td>\n",
       "      <td>2017-10-08T21:07:18Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>nikitasrivatsan/DeepLearningVideoGames</td>\n",
       "      <td>2015-11-03T01:34:13Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>recommenders-team/recommenders</td>\n",
       "      <td>2018-09-19T10:06:07Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  full_name            created_at\n",
       "0                     tensorflow/tensorflow  2015-11-07T01:19:20Z\n",
       "1                             opencv/opencv  2012-07-19T09:40:17Z\n",
       "2                          keras-team/keras  2015-03-28T00:35:42Z\n",
       "3                           pytorch/pytorch  2016-08-13T05:26:41Z\n",
       "4       scutan90/DeepLearning-500-questions  2018-06-27T06:36:45Z\n",
       "..                                      ...                   ...\n",
       "321                     sepandhaghighi/pycm  2018-01-22T19:46:54Z\n",
       "322                           isl-org/MiDaS  2019-06-24T14:08:35Z\n",
       "323   abdulfatir/twitter-sentiment-analysis  2017-10-08T21:07:18Z\n",
       "324  nikitasrivatsan/DeepLearningVideoGames  2015-11-03T01:34:13Z\n",
       "325          recommenders-team/recommenders  2018-09-19T10:06:07Z\n",
       "\n",
       "[326 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo = get_repo(\"./issue_data/combine1_TF_software.xlsx\")\n",
    "repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d9339ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo[\"created_at\"] = repo[\"created_at\"].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "752f50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "need_repos = [\n",
    "    \"deepfakes/faceswap\",\n",
    "    \"iperov/DeepFaceLab\",\n",
    "    \"deezer/spleeter\",\n",
    "    \"streamlit/streamlit\",\n",
    "    \"recommenders-team/recommenders\",\n",
    "    \"mozilla/TTS\",\n",
    "    \"JaidedAI/EasyOCR\",\n",
    "    \"junyanz/pytorch-CycleGAN-and-pix2pix\",\n",
    "    \"CorentinJ/Real-Time-Voice-Cloning\",\n",
    "    \"dusty-nv/jetson-inference\",\n",
    "    \"CMU-Perceptual-Computing-Lab/openpose\"\n",
    "]\n",
    "\n",
    "repo = repo[repo['full_name'].isin(need_repos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a36baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepfakes/faceswap</td>\n",
       "      <td>2017-12-19 09:44:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CorentinJ/Real-Time-Voice-Cloning</td>\n",
       "      <td>2019-05-26 08:56:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>iperov/DeepFaceLab</td>\n",
       "      <td>2018-06-04 13:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CMU-Perceptual-Computing-Lab/openpose</td>\n",
       "      <td>2017-04-24 14:06:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>deezer/spleeter</td>\n",
       "      <td>2019-09-26 15:40:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>streamlit/streamlit</td>\n",
       "      <td>2019-08-24 00:14:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>junyanz/pytorch-CycleGAN-and-pix2pix</td>\n",
       "      <td>2017-04-18 10:33:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>JaidedAI/EasyOCR</td>\n",
       "      <td>2020-03-14 11:46:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>mozilla/TTS</td>\n",
       "      <td>2018-01-23 14:22:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>dusty-nv/jetson-inference</td>\n",
       "      <td>2016-07-30 19:56:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>recommenders-team/recommenders</td>\n",
       "      <td>2018-09-19 10:06:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 full_name          created_at\n",
       "6                       deepfakes/faceswap 2017-12-19 09:44:13\n",
       "10       CorentinJ/Real-Time-Voice-Cloning 2019-05-26 08:56:15\n",
       "12                      iperov/DeepFaceLab 2018-06-04 13:10:00\n",
       "18   CMU-Perceptual-Computing-Lab/openpose 2017-04-24 14:06:31\n",
       "29                         deezer/spleeter 2019-09-26 15:40:46\n",
       "38                     streamlit/streamlit 2019-08-24 00:14:52\n",
       "39    junyanz/pytorch-CycleGAN-and-pix2pix 2017-04-18 10:33:05\n",
       "60                        JaidedAI/EasyOCR 2020-03-14 11:46:39\n",
       "127                            mozilla/TTS 2018-01-23 14:22:06\n",
       "130              dusty-nv/jetson-inference 2016-07-30 19:56:47\n",
       "325         recommenders-team/recommenders 2018-09-19 10:06:07"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbaa8074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_total_count_period(repo_name, since, until, per_page=1):\n",
    "    \"\"\"\n",
    "    get total issue counts of a repo during [since, until], per_page default value is 1\n",
    "    \"\"\"\n",
    "    # HEADERS = {'Authorization': 'token a386400773eef623d8c2c8dca6bed227d7036dab'}\n",
    "    HEADERS = {'Authorization': 'token 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'}\n",
    "\n",
    "    url = \"https://api.github.com/search/issues?q=repo:\" + repo_name + \"+is:issue+state:closed+created:SINCE..UNTIL&per_page=\" + str(\n",
    "        per_page)\n",
    "\n",
    "    day_url = url.replace('SINCE', since.strftime('%Y-%m-%dT%H:%M:%SZ')).replace('UNTIL', until.strftime(\n",
    "        '%Y-%m-%dT%H:%M:%SZ'))\n",
    "\n",
    "    print(day_url)\n",
    "    response = requests.get(day_url, headers=HEADERS)\n",
    "\n",
    "    # process the response status\n",
    "    pause_time = 1\n",
    "    while True:\n",
    "        if response.status_code == 200:\n",
    "            print(f\"{repo_name}, status_code: {response.status_code}\")\n",
    "            break\n",
    "        elif response.status_code == 403:\n",
    "            time.sleep(pause_time)\n",
    "            pause_time *= 2  # sleep 2^0 , 2^1, 2^2, ...\n",
    "            response = requests.get(day_url, headers=HEADERS)\n",
    "            print(f\"{repo_name}, pause time:{pause_time}s, status_code: {response.status_code}\")\n",
    "        else:\n",
    "            print(f\"response.status_code is {response.status_code}\")\n",
    "            break\n",
    "\n",
    "    if response.json().get(\"total_count\") is not None:\n",
    "        total_count = response.json()[\"total_count\"]  # get total count of issues\n",
    "    else:\n",
    "        total_count = 0\n",
    "    return total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "10171ed9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.github.com/search/issues?q=repo:deepfakes/faceswap+is:issue+state:closed+created:2017-12-19T09:44:13Z..2024-01-01T00:00:00Z&per_page=1\n",
      "deepfakes/faceswap, status_code: 200\n",
      "https://api.github.com/search/issues?q=repo:CorentinJ/Real-Time-Voice-Cloning+is:issue+state:closed+created:2019-05-26T08:56:15Z..2024-01-01T00:00:00Z&per_page=1\n",
      "CorentinJ/Real-Time-Voice-Cloning, status_code: 200\n",
      "https://api.github.com/search/issues?q=repo:iperov/DeepFaceLab+is:issue+state:closed+created:2018-06-04T13:10:00Z..2024-01-01T00:00:00Z&per_page=1\n",
      "iperov/DeepFaceLab, status_code: 200\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2017-04-24T14:06:31Z..2024-01-01T00:00:00Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "https://api.github.com/search/issues?q=repo:deezer/spleeter+is:issue+state:closed+created:2019-09-26T15:40:46Z..2024-01-01T00:00:00Z&per_page=1\n",
      "deezer/spleeter, status_code: 200\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2019-08-24T00:14:52Z..2024-01-01T00:00:00Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "https://api.github.com/search/issues?q=repo:junyanz/pytorch-CycleGAN-and-pix2pix+is:issue+state:closed+created:2017-04-18T10:33:05Z..2024-01-01T00:00:00Z&per_page=1\n",
      "junyanz/pytorch-CycleGAN-and-pix2pix, status_code: 200\n",
      "https://api.github.com/search/issues?q=repo:JaidedAI/EasyOCR+is:issue+state:closed+created:2020-03-14T11:46:39Z..2024-01-01T00:00:00Z&per_page=1\n",
      "JaidedAI/EasyOCR, status_code: 200\n",
      "https://api.github.com/search/issues?q=repo:mozilla/TTS+is:issue+state:closed+created:2018-01-23T14:22:06Z..2024-01-01T00:00:00Z&per_page=1\n",
      "mozilla/TTS, status_code: 200\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2016-07-30T19:56:47Z..2024-01-01T00:00:00Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "https://api.github.com/search/issues?q=repo:recommenders-team/recommenders+is:issue+state:closed+created:2018-09-19T10:06:07Z..2024-01-01T00:00:00Z&per_page=1\n",
      "recommenders-team/recommenders, status_code: 200\n"
     ]
    }
   ],
   "source": [
    "# 获取各仓库issue总数\n",
    "repo_issue_count = []\n",
    "\n",
    "for i in range(len(repo)):\n",
    "    repo_name, created_time = repo.iat[i, 0], repo.iloc[i, 1]\n",
    "    # until = datetime.today() - timedelta(days=2)\n",
    "    until = datetime(year=2024, month=1, day=1)\n",
    "\n",
    "    total_count = get_total_count_period(repo_name, created_time, until)\n",
    "    repo_issue_count.append(total_count)  # recode the total issues count of the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c2f51da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-82877eb4b95b>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  repo[\"issues_count\"] = repo_issue_count\n"
     ]
    }
   ],
   "source": [
    "repo[\"issues_count\"] = repo_issue_count\n",
    "repo.to_excel(\"./issue_data/repo_issue_count.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7edd9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_than_1000 = repo[repo[\"issues_count\"] < 1000]  # repos with issues less than 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4d30e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_1000 = repo[repo[\"issues_count\"] >= 1000]  # repos with issues more than 1000, include 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "051a2bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_issue(repo_name, since, until, page, per_page=30, start_page=0):\n",
    "    \"\"\"\n",
    "    get issues of repo for page=page ,per_page=per_page during [since: until]\n",
    "    strat_page is used for repo with more than 1000 issues, correct current page = start_page+page\n",
    "    \"\"\"\n",
    "    HEADERS = {'Authorization': 'token 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'}\n",
    "\n",
    "    url = \"https://api.github.com/search/issues?q=repo:\" + repo_name + \"+is:issue+state:closed+created:SINCE..UNTIL&per_page=\" + str(\n",
    "        per_page)\n",
    "\n",
    "    day_url = url.replace('SINCE', since.strftime('%Y-%m-%dT%H:%M:%SZ')).replace('UNTIL', until.strftime(\n",
    "        '%Y-%m-%dT%H:%M:%SZ'))\n",
    "\n",
    "    response = requests.get(day_url, params={'page': page}, headers=HEADERS)\n",
    "\n",
    "    # process the response status\n",
    "    pause_time = 1\n",
    "    while True:\n",
    "        if response.status_code == 200:\n",
    "            print(f\"{repo_name}, page:{start_page + page}, status_code: {response.status_code}\")\n",
    "            break\n",
    "        elif response.status_code == 403:\n",
    "            time.sleep(pause_time)\n",
    "            pause_time = pause_time * 2  # sleep 2^0 , 2^1, 2^2, ...\n",
    "            response = requests.get(day_url, params={'page': page}, headers=HEADERS)\n",
    "            print(\n",
    "                f\"{repo_name}, page:{start_page + page}, pause time:{pause_time}s, status_code: {response.status_code}\")\n",
    "        elif response.status_code == 422:  # More than 1000 issues\n",
    "            print(\n",
    "                f\"{repo_name}, page:{start_page + page}, pause time:{pause_time}s, status_code: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "    content_dict = response.json()\n",
    "    return content_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b54a8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_repo_dirs(project_path, dir_name ,repo_name):\n",
    "    # create issues directory\n",
    "    dir_path = os.path.join(project_path, dir_name)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "\n",
    "    # create repo directory\n",
    "    repo_dir_path = os.path.join(dir_path, repo_name)\n",
    "    if not os.path.exists(repo_dir_path):\n",
    "        os.mkdir(repo_dir_path)\n",
    "    \n",
    "    return repo_dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42146cb4",
   "metadata": {},
   "source": [
    "get issues for repo which issues less than 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3dc9ef08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(less_than_1000)):\n",
    "    repo_name, created_time = less_than_1000.iat[i, 0], less_than_1000.iloc[i, 1]\n",
    "    # until = datetime.today()\n",
    "    until = datetime(year=2024, month=1, day=1)\n",
    "    per_page = 100\n",
    "\n",
    "    total_count = less_than_1000.iat[i, 2]\n",
    "    pages = total_count // per_page + 1\n",
    "\n",
    "    # create repo dir\n",
    "    project_path = \"./issue_data\"\n",
    "    repo_dir_path = make_repo_dirs(project_path, \"issues\", repo_name.split(r'/')[1])\n",
    "\n",
    "    for page in range(pages):\n",
    "        content_dict = get_issue(repo_name, created_time, until, page + 1, per_page)  # note that real page start from 1\n",
    "\n",
    "        # save json file\n",
    "        file_path = os.path.join(repo_dir_path, str(page) + \".json\")\n",
    "\n",
    "        with open(file_path, \"w\") as w:\n",
    "            w.write(json.dumps(content_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29db80",
   "metadata": {},
   "source": [
    "get issues for repo which issues less than 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce76f716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2017-04-24T14:06:31Z..2017-07-23T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:1, status_code: 200\n",
      "write to ./issue_data/issues/openpose/0.json\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:2, status_code: 200\n",
      "write to ./issue_data/issues/openpose/1.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2017-07-23T14:06:31Z..2017-10-21T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:3, status_code: 200\n",
      "write to ./issue_data/issues/openpose/2.json\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:4, status_code: 200\n",
      "write to ./issue_data/issues/openpose/3.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2017-10-21T14:06:31Z..2018-01-19T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:5, status_code: 200\n",
      "write to ./issue_data/issues/openpose/4.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2018-01-19T14:06:31Z..2018-04-19T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:6, status_code: 200\n",
      "write to ./issue_data/issues/openpose/5.json\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:7, status_code: 200\n",
      "write to ./issue_data/issues/openpose/6.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2018-04-19T14:06:31Z..2018-07-18T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:8, status_code: 200\n",
      "write to ./issue_data/issues/openpose/7.json\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:9, status_code: 200\n",
      "write to ./issue_data/issues/openpose/8.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2018-07-18T14:06:31Z..2018-10-16T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:10, status_code: 200\n",
      "write to ./issue_data/issues/openpose/9.json\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:11, status_code: 200\n",
      "write to ./issue_data/issues/openpose/10.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2018-10-16T14:06:31Z..2019-01-14T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:12, status_code: 200\n",
      "write to ./issue_data/issues/openpose/11.json\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:13, status_code: 200\n",
      "write to ./issue_data/issues/openpose/12.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2019-01-14T14:06:31Z..2019-04-14T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:14, status_code: 200\n",
      "write to ./issue_data/issues/openpose/13.json\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:15, status_code: 200\n",
      "write to ./issue_data/issues/openpose/14.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2019-04-14T14:06:31Z..2019-07-13T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:16, status_code: 200\n",
      "write to ./issue_data/issues/openpose/15.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2019-07-13T14:06:31Z..2019-10-11T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:17, status_code: 200\n",
      "write to ./issue_data/issues/openpose/16.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2019-10-11T14:06:31Z..2020-01-09T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:18, status_code: 200\n",
      "write to ./issue_data/issues/openpose/17.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2020-01-09T14:06:31Z..2020-04-08T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:19, pause time:2s, status_code: 403\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:19, pause time:4s, status_code: 403\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:19, pause time:8s, status_code: 403\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:19, pause time:16s, status_code: 403\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:19, pause time:32s, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:19, status_code: 200\n",
      "write to ./issue_data/issues/openpose/18.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2020-04-08T14:06:31Z..2020-07-07T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:20, status_code: 200\n",
      "write to ./issue_data/issues/openpose/19.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2020-07-07T14:06:31Z..2020-10-05T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:21, status_code: 200\n",
      "write to ./issue_data/issues/openpose/20.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2020-10-05T14:06:31Z..2021-01-03T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:22, status_code: 200\n",
      "write to ./issue_data/issues/openpose/21.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2021-01-03T14:06:31Z..2021-04-03T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:23, status_code: 200\n",
      "write to ./issue_data/issues/openpose/22.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2021-04-03T14:06:31Z..2021-07-02T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:24, status_code: 200\n",
      "write to ./issue_data/issues/openpose/23.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2021-07-02T14:06:31Z..2021-09-30T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:25, status_code: 200\n",
      "write to ./issue_data/issues/openpose/24.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2021-09-30T14:06:31Z..2021-12-29T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:26, status_code: 200\n",
      "write to ./issue_data/issues/openpose/25.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2021-12-29T14:06:31Z..2022-03-29T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:27, status_code: 200\n",
      "write to ./issue_data/issues/openpose/26.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2022-03-29T14:06:31Z..2022-06-27T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:28, status_code: 200\n",
      "write to ./issue_data/issues/openpose/27.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2022-06-27T14:06:31Z..2022-09-25T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:29, status_code: 200\n",
      "write to ./issue_data/issues/openpose/28.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2022-09-25T14:06:31Z..2022-12-24T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:30, status_code: 200\n",
      "write to ./issue_data/issues/openpose/29.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2022-12-24T14:06:31Z..2023-03-24T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:31, status_code: 200\n",
      "write to ./issue_data/issues/openpose/30.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2023-03-24T14:06:31Z..2023-06-22T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:32, status_code: 200\n",
      "write to ./issue_data/issues/openpose/31.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2023-06-22T14:06:31Z..2023-09-20T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:33, status_code: 200\n",
      "write to ./issue_data/issues/openpose/32.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2023-09-20T14:06:31Z..2023-12-19T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:34, pause time:2s, status_code: 403\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:34, pause time:4s, status_code: 403\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:34, pause time:8s, status_code: 403\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:34, pause time:16s, status_code: 403\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:34, pause time:32s, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:34, status_code: 200\n",
      "write to ./issue_data/issues/openpose/33.json\n",
      "https://api.github.com/search/issues?q=repo:CMU-Perceptual-Computing-Lab/openpose+is:issue+state:closed+created:2023-12-19T14:06:31Z..2024-03-18T14:06:31Z&per_page=1\n",
      "CMU-Perceptual-Computing-Lab/openpose, status_code: 200\n",
      "CMU-Perceptual-Computing-Lab/openpose, page:35, status_code: 200\n",
      "write to ./issue_data/issues/openpose/34.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2019-08-24T00:14:52Z..2019-11-22T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:1, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/0.json\n",
      "streamlit/streamlit, page:2, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/1.json\n",
      "streamlit/streamlit, page:3, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/2.json\n",
      "streamlit/streamlit, page:4, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/3.json\n",
      "streamlit/streamlit, page:5, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/4.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2019-11-22T00:14:52Z..2020-02-20T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:6, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/5.json\n",
      "streamlit/streamlit, page:7, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/6.json\n",
      "streamlit/streamlit, page:8, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/7.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2020-02-20T00:14:52Z..2020-05-20T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:9, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/8.json\n",
      "streamlit/streamlit, page:10, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/9.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2020-05-20T00:14:52Z..2020-08-18T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:11, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/10.json\n",
      "streamlit/streamlit, page:12, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/11.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2020-08-18T00:14:52Z..2020-11-16T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:13, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/12.json\n",
      "streamlit/streamlit, page:14, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/13.json\n",
      "streamlit/streamlit, page:15, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/14.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2020-11-16T00:14:52Z..2021-02-14T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:16, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/15.json\n",
      "streamlit/streamlit, page:17, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/16.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2021-02-14T00:14:52Z..2021-05-15T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:18, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/17.json\n",
      "streamlit/streamlit, page:19, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/18.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2021-05-15T00:14:52Z..2021-08-13T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:20, pause time:2s, status_code: 403\n",
      "streamlit/streamlit, page:20, pause time:4s, status_code: 403\n",
      "streamlit/streamlit, page:20, pause time:8s, status_code: 403\n",
      "streamlit/streamlit, page:20, pause time:16s, status_code: 403\n",
      "streamlit/streamlit, page:20, pause time:32s, status_code: 200\n",
      "streamlit/streamlit, page:20, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/19.json\n",
      "streamlit/streamlit, page:21, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/20.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2021-08-13T00:14:52Z..2021-11-11T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:22, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/21.json\n",
      "streamlit/streamlit, page:23, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/22.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2021-11-11T00:14:52Z..2022-02-09T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:24, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/23.json\n",
      "streamlit/streamlit, page:25, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/24.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2022-02-09T00:14:52Z..2022-05-10T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:26, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/25.json\n",
      "streamlit/streamlit, page:27, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/26.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2022-05-10T00:14:52Z..2022-08-08T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:28, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/27.json\n",
      "streamlit/streamlit, page:29, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/28.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2022-08-08T00:14:52Z..2022-11-06T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:30, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/29.json\n",
      "streamlit/streamlit, page:31, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/30.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2022-11-06T00:14:52Z..2023-02-04T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:32, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/31.json\n",
      "streamlit/streamlit, page:33, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/32.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2023-02-04T00:14:52Z..2023-05-05T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:34, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/33.json\n",
      "streamlit/streamlit, page:35, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/34.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2023-05-05T00:14:52Z..2023-08-03T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:36, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/35.json\n",
      "streamlit/streamlit, page:37, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/36.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2023-08-03T00:14:52Z..2023-11-01T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:38, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/37.json\n",
      "streamlit/streamlit, page:39, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/38.json\n",
      "https://api.github.com/search/issues?q=repo:streamlit/streamlit+is:issue+state:closed+created:2023-11-01T00:14:52Z..2024-01-30T00:14:52Z&per_page=1\n",
      "streamlit/streamlit, status_code: 200\n",
      "streamlit/streamlit, page:40, pause time:2s, status_code: 403\n",
      "streamlit/streamlit, page:40, pause time:4s, status_code: 403\n",
      "streamlit/streamlit, page:40, pause time:8s, status_code: 403\n",
      "streamlit/streamlit, page:40, pause time:16s, status_code: 403\n",
      "streamlit/streamlit, page:40, pause time:32s, status_code: 200\n",
      "streamlit/streamlit, page:40, status_code: 200\n",
      "write to ./issue_data/issues/streamlit/39.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2016-07-30T19:56:47Z..2016-10-28T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:1, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/0.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2016-10-28T19:56:47Z..2017-01-26T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:2, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/1.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2017-01-26T19:56:47Z..2017-04-26T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:3, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/2.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2017-04-26T19:56:47Z..2017-07-25T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:4, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/3.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2017-07-25T19:56:47Z..2017-10-23T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:5, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/4.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2017-10-23T19:56:47Z..2018-01-21T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:6, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/5.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2018-01-21T19:56:47Z..2018-04-21T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:7, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/6.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2018-04-21T19:56:47Z..2018-07-20T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:8, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/7.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2018-07-20T19:56:47Z..2018-10-18T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:9, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/8.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2018-10-18T19:56:47Z..2019-01-16T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:10, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/9.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2019-01-16T19:56:47Z..2019-04-16T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:11, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/10.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2019-04-16T19:56:47Z..2019-07-15T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:12, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/11.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2019-07-15T19:56:47Z..2019-10-13T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:13, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/12.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2019-10-13T19:56:47Z..2020-01-11T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:14, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/13.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2020-01-11T19:56:47Z..2020-04-10T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:15, pause time:2s, status_code: 403\n",
      "dusty-nv/jetson-inference, page:15, pause time:4s, status_code: 403\n",
      "dusty-nv/jetson-inference, page:15, pause time:8s, status_code: 403\n",
      "dusty-nv/jetson-inference, page:15, pause time:16s, status_code: 403\n",
      "dusty-nv/jetson-inference, page:15, pause time:32s, status_code: 200\n",
      "dusty-nv/jetson-inference, page:15, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/14.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2020-04-10T19:56:47Z..2020-07-09T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:16, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/15.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2020-07-09T19:56:47Z..2020-10-07T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:17, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/16.json\n",
      "dusty-nv/jetson-inference, page:18, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/17.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2020-10-07T19:56:47Z..2021-01-05T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:19, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/18.json\n",
      "dusty-nv/jetson-inference, page:20, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/19.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2021-01-05T19:56:47Z..2021-04-05T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:21, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/20.json\n",
      "dusty-nv/jetson-inference, page:22, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/21.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2021-04-05T19:56:47Z..2021-07-04T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:23, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/22.json\n",
      "dusty-nv/jetson-inference, page:24, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/23.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2021-07-04T19:56:47Z..2021-10-02T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:25, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/24.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2021-10-02T19:56:47Z..2021-12-31T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:26, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/25.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2021-12-31T19:56:47Z..2022-03-31T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:27, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/26.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2022-03-31T19:56:47Z..2022-06-29T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:28, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/27.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2022-06-29T19:56:47Z..2022-09-27T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:29, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/28.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2022-09-27T19:56:47Z..2022-12-26T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:30, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/29.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2022-12-26T19:56:47Z..2023-03-26T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:31, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/30.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2023-03-26T19:56:47Z..2023-06-24T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:32, pause time:2s, status_code: 403\n",
      "dusty-nv/jetson-inference, page:32, pause time:4s, status_code: 403\n",
      "dusty-nv/jetson-inference, page:32, pause time:8s, status_code: 403\n",
      "dusty-nv/jetson-inference, page:32, pause time:16s, status_code: 403\n",
      "dusty-nv/jetson-inference, page:32, pause time:32s, status_code: 200\n",
      "dusty-nv/jetson-inference, page:32, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/31.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2023-06-24T19:56:47Z..2023-09-22T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:33, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/32.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2023-09-22T19:56:47Z..2023-12-21T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:34, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/33.json\n",
      "https://api.github.com/search/issues?q=repo:dusty-nv/jetson-inference+is:issue+state:closed+created:2023-12-21T19:56:47Z..2024-03-20T19:56:47Z&per_page=1\n",
      "dusty-nv/jetson-inference, status_code: 200\n",
      "dusty-nv/jetson-inference, page:35, status_code: 200\n",
      "write to ./issue_data/issues/jetson-inference/34.json\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(more_than_1000)):\n",
    "    repo_name, created_time = more_than_1000.iat[i, 0], more_than_1000.iloc[i, 1]\n",
    "\n",
    "    since = deepcopy(created_time)  # use deepy copy , avoid modifying `repo` Dataframe\n",
    "    period = timedelta(days=90)  # 90 days for a query\n",
    "    # until = datetime.today()\n",
    "    until = datetime(year=2024, month=1, day=1)\n",
    "\n",
    "    per_page = 100\n",
    "    total_pages = 0  # total page for repo, is used to name the json file\n",
    "\n",
    "    # create repo dir\n",
    "    project_path = \"./issue_data\"\n",
    "    repo_dir_path = make_repo_dirs(project_path, \"issues\", repo_name.split(r'/')[1])\n",
    "\n",
    "    while since < until:\n",
    "        quarter_total_count = get_total_count_period(repo_name, since, since + period)\n",
    "\n",
    "        if quarter_total_count == 0:\n",
    "            since += period\n",
    "            continue\n",
    "            \n",
    "        pages = quarter_total_count // per_page + 1\n",
    "\n",
    "        for page in range(pages):\n",
    "            content_dict = get_issue(repo_name, since, since + period, page + 1, per_page,\n",
    "                                    total_pages)  # note that real page start from 1\n",
    "\n",
    "            # save json file\n",
    "            file_path = os.path.join(repo_dir_path, str(total_pages + page) + \".json\")\n",
    "\n",
    "            with open(file_path, \"w\") as w:\n",
    "                w.write(json.dumps(content_dict))\n",
    "            print(f\"write to {file_path}\")\n",
    "\n",
    "        since += period  # move to next month\n",
    "        total_pages += pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f6ddeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12023"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo[\"issues_count\"][:50].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "681a64a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"./issue_data\" \n",
    "# issue_path = os.path.join(project_path, \"issues\")\n",
    "issue_path = os.path.join(project_path, \"issues_with_comments\")\n",
    "\n",
    "issue_dict = {}\n",
    "needed_list = [\"id\", \"node_id\", \"number\", \"html_url\", \"title\", \"body\", \"comments\"]\n",
    "\n",
    "# for i in range(4):\n",
    "for i in range(len(repo)):\n",
    "    repo_name = repo.iat[i, 0]\n",
    "    \n",
    "    # generate repo dir\n",
    "    repo_dir_path = os.path.join(issue_path, repo_name.split(r'/')[1])\n",
    "    \n",
    "    # sort files by name \n",
    "    all_files = list(os.listdir(repo_dir_path))\n",
    "    all_files.sort(key=lambda x: int(x.split(r'.')[0]))\n",
    "    \n",
    "    for file in all_files:\n",
    "        with open(os.path.join(repo_dir_path, file), 'r') as f:\n",
    "            dic = json.load(f)\n",
    "    \n",
    "            # traverse all issues\n",
    "            for item in dic[\"items\"]:\n",
    "                key = repo_name.split(r'/')[1] + '_' + str(item.get('number'))\n",
    "\n",
    "                comment_list = item[\"comments_list\"]\n",
    "                comment_strs = []\n",
    "                for comment in comment_list:\n",
    "                    comment_strs.append(comment[\"body\"])\n",
    "                commment_concat_str = \" CONCATCOMMENTSIGN \".join(comment_strs)\n",
    "\n",
    "                issue_dict[key] = {\n",
    "                    **{\"fullname\": repo_name, \"name\":repo_name.split(r'/')[1].lower()}, # 'name' is used for sorting, remove later\n",
    "                    **{x:item[x] for x in needed_list},\n",
    "                    **{\"commment_concat_str\": commment_concat_str}\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b6320f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(issue_dict)\n",
    "df = df.T\n",
    "df = df.sort_values(by=['name', \"number\"], ascending=True)\n",
    "df = df.drop(axis=1, columns=\"name\") # drop column 'name', it is used for sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "803a93ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>comments</th>\n",
       "      <th>commment_concat_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TTS_747</th>\n",
       "      <td>mozilla/TTS</td>\n",
       "      <td>1189411846</td>\n",
       "      <td>I_kwDOBxIBp85G5PwG</td>\n",
       "      <td>747</td>\n",
       "      <td>https://github.com/mozilla/TTS/issues/747</td>\n",
       "      <td>THIS REPO IS NOT MAINTAINED -- USE https://git...</td>\n",
       "      <td>This repo obviously is not maintained and it w...</td>\n",
       "      <td>1</td>\n",
       "      <td>This issue has been automatically marked as st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTS_749</th>\n",
       "      <td>mozilla/TTS</td>\n",
       "      <td>1213465664</td>\n",
       "      <td>I_kwDOBxIBp85IVARA</td>\n",
       "      <td>749</td>\n",
       "      <td>https://github.com/mozilla/TTS/issues/749</td>\n",
       "      <td>Missing `f` prefix on f-strings</td>\n",
       "      <td>Some strings looks like they're meant to be f-...</td>\n",
       "      <td>1</td>\n",
       "      <td>This issue has been automatically marked as st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTS_751</th>\n",
       "      <td>mozilla/TTS</td>\n",
       "      <td>1213644088</td>\n",
       "      <td>I_kwDOBxIBp85IVr04</td>\n",
       "      <td>751</td>\n",
       "      <td>https://github.com/mozilla/TTS/issues/751</td>\n",
       "      <td>Installation in python venv fails armx64</td>\n",
       "      <td>Installing tts in a python venv on macOS fails...</td>\n",
       "      <td>3</td>\n",
       "      <td>Same Issue here. M1 Pro, macOS 12.3.1, Python ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTS_752</th>\n",
       "      <td>mozilla/TTS</td>\n",
       "      <td>1256045732</td>\n",
       "      <td>I_kwDOBxIBp85K3byk</td>\n",
       "      <td>752</td>\n",
       "      <td>https://github.com/mozilla/TTS/issues/752</td>\n",
       "      <td>hangup. server crash</td>\n",
       "      <td>hello, thanks for the project. It's amazing wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>The issue seems to be solved by adding a littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTS_754</th>\n",
       "      <td>mozilla/TTS</td>\n",
       "      <td>1286789052</td>\n",
       "      <td>I_kwDOBxIBp85Mste8</td>\n",
       "      <td>754</td>\n",
       "      <td>https://github.com/mozilla/TTS/issues/754</td>\n",
       "      <td>Trainer stops working without error messages</td>\n",
       "      <td>I'm trying to train TTS for a custom dataset (...</td>\n",
       "      <td>1</td>\n",
       "      <td>This issue has been automatically marked as st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fullname          id             node_id number  \\\n",
       "TTS_747  mozilla/TTS  1189411846  I_kwDOBxIBp85G5PwG    747   \n",
       "TTS_749  mozilla/TTS  1213465664  I_kwDOBxIBp85IVARA    749   \n",
       "TTS_751  mozilla/TTS  1213644088  I_kwDOBxIBp85IVr04    751   \n",
       "TTS_752  mozilla/TTS  1256045732  I_kwDOBxIBp85K3byk    752   \n",
       "TTS_754  mozilla/TTS  1286789052  I_kwDOBxIBp85Mste8    754   \n",
       "\n",
       "                                          html_url  \\\n",
       "TTS_747  https://github.com/mozilla/TTS/issues/747   \n",
       "TTS_749  https://github.com/mozilla/TTS/issues/749   \n",
       "TTS_751  https://github.com/mozilla/TTS/issues/751   \n",
       "TTS_752  https://github.com/mozilla/TTS/issues/752   \n",
       "TTS_754  https://github.com/mozilla/TTS/issues/754   \n",
       "\n",
       "                                                     title  \\\n",
       "TTS_747  THIS REPO IS NOT MAINTAINED -- USE https://git...   \n",
       "TTS_749                    Missing `f` prefix on f-strings   \n",
       "TTS_751           Installation in python venv fails armx64   \n",
       "TTS_752                               hangup. server crash   \n",
       "TTS_754       Trainer stops working without error messages   \n",
       "\n",
       "                                                      body comments  \\\n",
       "TTS_747  This repo obviously is not maintained and it w...        1   \n",
       "TTS_749  Some strings looks like they're meant to be f-...        1   \n",
       "TTS_751  Installing tts in a python venv on macOS fails...        3   \n",
       "TTS_752  hello, thanks for the project. It's amazing wh...        1   \n",
       "TTS_754  I'm trying to train TTS for a custom dataset (...        1   \n",
       "\n",
       "                                       commment_concat_str  \n",
       "TTS_747  This issue has been automatically marked as st...  \n",
       "TTS_749  This issue has been automatically marked as st...  \n",
       "TTS_751  Same Issue here. M1 Pro, macOS 12.3.1, Python ...  \n",
       "TTS_752  The issue seems to be solved by adding a littl...  \n",
       "TTS_754  This issue has been automatically marked as st...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6f60485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xlsxwriter/worksheet.py:1252: UserWarning: Ignoring URL 'https://github.com/CMU-Perceptual-Computing-Lab/openpose/pull/786/commits/21eac3784c608a8b25162cae058cfb526f4cd673\n",
      "\n",
      "\n",
      "\n",
      "Is%20this%20a%20solution?%20CONCATCOMMENTSIGN%20That%20looks%20great,%20thanks!%20CONCATCOMMENTSIGN%20%3e%20That%20looks%20great,%20thanks!\n",
      "\n",
      "I%20tried%20but%20failed,how%20about%20you.%20CONCATCOMMENTSIGN%20I%20haven't%20had%20the%20time%20yet.%20I%20will%20as%20soon%20as%20possible,%20but%20that%20will%20probably%20be%20in%20a%20few%20weeks.%20CONCATCOMMENTSIGN%20%3e%20%5b21eac37%5d(https://github.com/CMU-Perceptual-Computing-Lab/openpose/commit/21eac3784c608a8b25162cae058cfb526f4cd673)\n",
      "%3e%20\n",
      "%3e%20Is%20this%20a%20solution?\n",
      "\n",
      "Yes,%20it%20works%20fine%20when%20at%20least%20one%20person%20exists%20in%20a%20image.%20\n",
      "It%20fails%20when%20the%20image%20(video)%20contains%20no%20person.\n",
      "I%20think%20it%20needs%20some%20codes%20for%20that%20case.\n",
      "\n",
      "To%20solve%20the%20exceptional%20case,%20I%20insert%20code%20%22if%20hands_array.size%20%3e%200:%22%20before%20the%20line%20128%20in%20openpose.py.%20This%20prevents%20'getHandOutputs'%20from%20execution%20when%20a%20image%20has%20no%20person.%20CONCATCOMMENTSIGN%20%3e%20%3e%20%5b21eac37%5d(https://github.com/CMU-Perceptual-Computing-Lab/openpose/commit/21eac3784c608a8b25162cae058cfb526f4cd673)\n",
      "%3e%20%3e%20Is%20this%20a%20solution?\n",
      "%3e%20\n",
      "%3e%20Yes,%20it%20works%20fine%20when%20at%20least%20one%20person%20exists%20in%20a%20image.\n",
      "%3e%20It%20fails%20when%20the%20image%20(video)%20contains%20no%20person.\n",
      "%3e%20I%20think%20it%20needs%20some%20codes%20for%20that%20case.\n",
      "%3e%20\n",
      "%3e%20To%20solve%20the%20exceptional%20case,%20I%20insert%20code%20%22if%20hands_array.size%20%3e%200:%22%20before%20the%20line%20128%20in%20openpose.py.%20This%20prevents%20'getHandOutputs'%20from%20execution%20when%20a%20image%20has%20no%20person.\n",
      "\n",
      "I%20tried%20several%20times%20on%20different%20machines,%20and%20finally%20failed.%20CONCATCOMMENTSIGN%20i%20need%20face%20thanks!%20should%20the%20create%20a%20pull%20request_?%20CONCATCOMMENTSIGN%2021eac37%20is%20ok%20for%20hand%20keypoints%20detection?\n",
      "Is%20there%20anyone%20update%20for%20answer%20for%20this?%20CONCATCOMMENTSIGN%20%3e%20%5b21eac37%5d(https://github.com/CMU-Perceptual-Computing-Lab/openpose/commit/21eac3784c608a8b25162cae058cfb526f4cd673)%20is%20ok%20for%20hand%20keypoints%20detection?\n",
      "%3e%20Is%20there%20anyone%20update%20for%20answer%20for%20this?\n",
      "\n",
      "yes,%20it%20works.%20change%20the%20source%20codes%20and%20build%20them.%20%20CONCATCOMMENTSIGN%20%3e%20%3e%20%5b21eac37%5d(https://github.com/CMU-Perceptual-Computing-Lab/openpose/commit/21eac3784c608a8b25162cae058cfb526f4cd673)%20is%20ok%20for%20hand%20keypoints%20detection?\n",
      "%3e%20%3e%20Is%20there%20anyone%20update%20for%20answer%20for%20this?\n",
      "%3e%20\n",
      "%3e%20yes,%20it%20works.%20change%20the%20source%20codes%20and%20build%20them.\n",
      "\n",
      "When%20there%20are%20many%20people,%20how%20do%20we%20know%20whose%20hands%20are?%20CONCATCOMMENTSIGN%20This%20issue%20has%20been%20automatically%20marked%20as%20stale%20because%20it%20has%20not%20had%20recent%20activity.%20It%20will%20be%20closed%20if%20no%20further%20activity%20occurs.%20Thank%20you%20for%20your%20contributions.\n",
      "' with link or location/anchor > 2079 characters since it exceeds Excel's limit for URLS\n",
      "  warn(\n",
      "/opt/conda/lib/python3.8/site-packages/xlsxwriter/worksheet.py:1252: UserWarning: Ignoring URL 'https://github.com/deepfakes/faceswap/pull/151%20CONCATCOMMENTSIGN%20@subzerofun%20no%20problem%20for%20this%20issue.%20As%20long%20as%20you%20try%20contributing,%20it%20is%20always%20welcome.%20Even%20better%20you%20could%20have%20pushed%20a%20pull%20request%20so%20that%20people%20can%20directly%20checkout%20your%20code%20and%20try%20to%20debug.\n",
      "\n",
      "As%20Shaoanlu%20stated,%20you%20can%20have%20a%20look%20at%20the%20GAN%20128%20plugin,%20or%20directly%20at%20faceswap-GAN%20repo%20CONCATCOMMENTSIGN%20@Clorr%20@shaoanlu%20Thanks,%20did%20take%20a%20look%20at%20your%20modified%20%60random_warp%60%20function%20from%20' with link or location/anchor > 2079 characters since it exceeds Excel's limit for URLS\n",
      "  warn(\n",
      "/opt/conda/lib/python3.8/site-packages/xlsxwriter/worksheet.py:1252: UserWarning: Ignoring URL 'https://faceswap.dev/forum/viewtopic.php?f=5&t=17%20CONCATCOMMENTSIGN%20I%20didn't%20understand%20the%20answer.%20As%20I%20said,%20I%20don't%20know%20the%20way%20to%20install%20standart%20driver%20on%20laptop,%20i%20tried%20two%20ways.%20I%20get%20this%20%22System%20Information%22:\n",
      "\n",
      "%60%60%60\n",
      "============%20System%20Information%20============\n",
      "encoding:%20%20%20%20%20%20%20%20%20%20%20%20cp1251\n",
      "git_branch:%20%20%20%20%20%20%20%20%20%20master\n",
      "git_commits:%20%20%20%20%20%20%20%20%209a000f9%20Merge%20branch%20'master'%20into%20staging\n",
      "gpu_cuda:%20%20%20%20%20%20%20%20%20%20%20%2010.0\n",
      "gpu_cudnn:%20%20%20%20%20%20%20%20%20%20%207.6.2\n",
      "gpu_devices:%20%20%20%20%20%20%20%20%20GPU_0:%20GeForce%20RTX%202060\n",
      "gpu_devices_active:%20%20GPU_0\n",
      "gpu_driver:%20%20%20%20%20%20%20%20%20%20431.60\n",
      "gpu_vram:%20%20%20%20%20%20%20%20%20%20%20%20GPU_0:%206144MB\n",
      "os_machine:%20%20%20%20%20%20%20%20%20%20AMD64\n",
      "os_platform:%20%20%20%20%20%20%20%20%20Windows-10-10.0.18362-SP0\n",
      "os_release:%20%20%20%20%20%20%20%20%20%2010\n",
      "py_command:%20%20%20%20%20%20%20%20%20%20C:\\Users\\Vadim\\faceswap/faceswap.py%20gui\n",
      "py_conda_version:%20%20%20%20conda%204.7.10\n",
      "py_implementation:%20%20%20CPython\n",
      "py_version:%20%20%20%20%20%20%20%20%20%203.6.9\n",
      "py_virtual_env:%20%20%20%20%20%20True\n",
      "sys_cores:%20%20%20%20%20%20%20%20%20%20%2012\n",
      "sys_processor:%20%20%20%20%20%20%20Intel64%20Family%206%20Model%20158%20Stepping%2010,%20GenuineIntel\n",
      "sys_ram:%20%20%20%20%20%20%20%20%20%20%20%20%20Total:%2016233MB,%20Available:%2010853MB,%20Used:%205380MB,%20Free:%2010853MB\n",
      "\n",
      "===============%20Pip%20Packages%20===============\n",
      "absl-py==0.7.1\n",
      "astor==0.7.1\n",
      "certifi==2019.6.16\n",
      "cloudpickle==1.2.1\n",
      "cycler==0.10.0\n",
      "cytoolz==0.10.0\n",
      "dask==2.1.0\n",
      "decorator==4.4.0\n",
      "fastcluster==1.1.25\n",
      "ffmpy==0.2.2\n",
      "gast==0.2.2\n",
      "grpcio==1.16.1\n",
      "h5py==2.9.0\n",
      "imageio==2.5.0\n",
      "imageio-ffmpeg==0.3.0\n",
      "joblib==0.13.2\n",
      "Keras==2.2.4\n",
      "Keras-Applications==1.0.8\n",
      "Keras-Preprocessing==1.1.0\n",
      "kiwisolver==1.1.0\n",
      "Markdown==3.1.1\n",
      "matplotlib==2.2.2\n",
      "mkl-fft==1.0.12\n",
      "mkl-random==1.0.2\n",
      "mkl-service==2.0.2\n",
      "mock==3.0.5\n",
      "networkx==2.3\n",
      "numpy==1.16.2\n",
      "nvidia-ml-py3==7.352.1\n",
      "olefile==0.46\n",
      "opencv-python==4.1.0.25\n",
      "pathlib==1.0.1\n",
      "Pillow==6.1.0\n",
      "protobuf==3.8.0\n",
      "psutil==5.6.3\n",
      "pyparsing==2.4.0\n",
      "pyreadline==2.1\n",
      "python-dateutil==2.8.0\n",
      "pytz==2019.1\n",
      "PyWavelets==1.0.3\n",
      "pywin32==223\n",
      "PyYAML==5.1.1\n",
      "scikit-image==0.15.0\n",
      "scikit-learn==0.21.2\n",
      "scipy==1.3.0\n",
      "six==1.12.0\n",
      "tensorboard==1.13.1\n",
      "tensorflow==1.13.1\n",
      "tensorflow-estimator==1.13.0\n",
      "termcolor==1.1.0\n",
      "toolz==0.10.0\n",
      "toposort==1.5\n",
      "tornado==6.0.3\n",
      "tqdm==4.32.1\n",
      "Werkzeug==0.15.4\n",
      "wincertstore==0.2\n",
      "\n",
      "==============%20Conda%20Packages%20==============\n",
      "' with link or location/anchor > 2079 characters since it exceeds Excel's limit for URLS\n",
      "  warn(\n",
      "/opt/conda/lib/python3.8/site-packages/xlsxwriter/worksheet.py:1252: UserWarning: Ignoring URL 'https://developer.nvidia.com/deepstream-sdk\n",
      "\n",
      "Or\n",
      "\n",
      "%60%60%60\n",
      "import%20cv2\n",
      "import%20time\n",
      "import%20threading\n",
      "\n",
      "global%20video_frame\n",
      "video_frame%20=%20None\n",
      "\n",
      "global%20thread_lock%20\n",
      "thread_lock%20=%20threading.Lock()\n",
      "\n",
      "GSTREAMER_PIPELINE%20=%20(\n",
      "%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'rtspsrc%20location=rtsp%20latency=300%20!'\n",
      "%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'rtph264depay%20!%20h264parse%20!'\n",
      "%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'queue%20max-size-buffers=10%20leaky=2%20!'\n",
      "%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'omxh264dec%20enable-max-performance=1%20enable-low-outbuffer=1%20!'\n",
      "%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'video/x-raw(memory:NVMM)%20,%20format=(string)NV12%20!'\n",
      "%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'nvvidconv%20!%20video/x-raw%20,%20width=450%20,%20height=450%20,%20format=(string)BGRx%20!'\n",
      "%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'videorate%20!%20video/x-raw%20,%20framerate=(fraction)10/1%20!'\n",
      "%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'videoconvert%20!%20'\n",
      "%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'appsink%20drop=1%20sync=0%20')\n",
      "\n",
      "video_stream%20=%20cv2.VideoCapture(gstream_elemets,%20cv2.CAP_GSTREAMER)\n",
      "\n",
      "def%20captureFrames():\n",
      "%20%20%20%20global%20video_frame,%20thread_lock\n",
      "\n",
      "%20%20%20%20' with link or location/anchor > 2079 characters since it exceeds Excel's limit for URLS\n",
      "  warn(\n",
      "/opt/conda/lib/python3.8/site-packages/xlsxwriter/worksheet.py:1252: UserWarning: Ignoring URL 'https://github.com/pseeth/pytorch-stft%20seems%20useful%20CONCATCOMMENTSIGN%20Now%20I%20try%20to%20adapt%20the%20above%20repo.%20It%20seems%20slower%20in%20training%20but%20much%20faster%20in%20on%20GPU%20test%20time%20.%20CONCATCOMMENTSIGN%20@erogol%20could%20you%20show%20some%20example%20that%20using%20%20%5bhttps://github.com/pseeth/pytorch-stft%5d(https://github.com/pseeth/pytorch-stft)%20CONCATCOMMENTSIGN%20@tsungruihon%20I%20don't%20have%20related%20files%20anymore.%20But%20should%20be%20easy%20for%20you%20to%20try%20it.%20Just%20replace%20things%20with%20https://github.com/pseeth/pytorch-stft%20.\n",
      "\n",
      "Or%20if%20you%20like%20to%20test%20the%20runtime%20speed,%20just%20compare%20it%20with%20librosa%20with%20random%20vectors.%20CONCATCOMMENTSIGN%20Thanks%20erogol.%20@erogol%20%20CONCATCOMMENTSIGN%20Now%20i%20have%20figured%20out%20the%20normal%20audio%20sound.%20But%20it%20seems%20that%20the%20%5bPyTorch%20griffin%20lim%5d(https://github.com/NVIDIA/tacotron2/blob/master/audio_processing.py' with link or location/anchor > 2079 characters since it exceeds Excel's limit for URLS\n",
      "  warn(\n",
      "/opt/conda/lib/python3.8/site-packages/xlsxwriter/worksheet.py:1252: UserWarning: Ignoring URL 'https://github.com/mozilla/TTS/issues/171' with link or location/anchor > 2079 characters since it exceeds Excel's limit for URLS\n",
      "  warn(\n",
      "/opt/conda/lib/python3.8/site-packages/xlsxwriter/worksheet.py:1252: UserWarning: Ignoring URL 'https://github.com/streamlit/streamlit/pull/593%20has%20a%20dockerfile%20that%20works,%20exercises%20most%20of%20the%20dev%20functionality%20and%20builds%20a%20release.%20%20I'm%20mostly%20thinking%20about%20how%20to%20integrate%20it%20with%20circleci%20config%20to%20make%20sure%20we%20don't%20lose%20that%20capability%20again.%20CONCATCOMMENTSIGN%20Hi%20Matthias,\n",
      "\n",
      "%60e2e/Dockerfile%60%20is%20not%20used%20by%20CircleCI.%20It's%20used%20by%20developers%20to%20run%20our%20e2e%20tests%20locally%20in%20a%20linux%20environment%20that%20matches%20our%20CircleCI%20environment.%20In%20particular%20we%20use%20it%20to%20generate%20our%20Cypress%20snapshots%20since%20there%20are%20differences%20in%20the%20snapshots%20when%20running%20on%20a%20linux%20vs%20mac,%20or%20on%20different%20linux%20distros.\n",
      "\n",
      "The%20image%20is%20built%20with%20%60make%20build-circleci%60%20and%20the%20container%20launched%20with%20%60make%20run-circleci%60.\n",
      "\n",
      "You'll%20see%20we%20use%20%60docker-compose%60%20to%20mount%20local%20volumes%20so%20we%20can%20make%20changes%20to%20our%20code%20and%20easily%20re-run%20the%20tests%20without%20re-building%20the%20image.%20Certain%20things%20are%20expected%20to%20be%20built%20on%20the%20host%20instead%20of%20in%20the%20container,%20for%20ex%20the%20protos,%20which%20is%20why%20we%20don't%20run%20%60make%20protobuf%60%20in%20the%20container.\n",
      "\n",
      "If%20%60make%20build-circleci%60%20and%20%60make%20run-circleci%60%20aren't%20working%20for%20you,%20please%20re-open.%20CONCATCOMMENTSIGN%20Hi%20Jonathan,\n",
      "\n",
      "%60make%20build-circleci%60%20just%20runs%20%60docker%20build%20-t%20streamlit_circleci%20-f%20e2e/Dockerfile%20.%60%20which%20is%20essentially%20the%20same%20as%20%60docker%20build%20-f%20e2e/Dockerfile%20-t%20streamlit-e2e-test-image%20.%60.%20%20So%20it%20fails%20with%20exactly%20the%20same%20problems.\n",
      "\n",
      "I%20updated%20the%20issue%20to%20reflect%20that%20%60make%20build-circleci%60%20is%20also%20broken.%20CONCATCOMMENTSIGN%20@jrhone%20I'd%20love%20to%20re-open,%20but%20it's%20disabled.%20CONCATCOMMENTSIGN%20@jrhone%20Thanks!%20CONCATCOMMENTSIGN%20@matthiasgoergens%20fix%20on%20the%20way%20via%20https://github.com/streamlit/streamlit/pull/639%20:)%20CONCATCOMMENTSIGN%20Fix%20was%20merged,%20so%20closing.' with link or location/anchor > 2079 characters since it exceeds Excel's limit for URLS\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import xlsxwriter\n",
    "grouped = df.groupby('fullname')\n",
    "df_dict = {name: group for name, group in grouped}\n",
    "date = datetime(year=2024, month=1, day=1).strftime(\"%Y_%m_%d\")  # 获取当前日期并格式化为年_月_日\n",
    "\n",
    "for key, value in df_dict.items():\n",
    "    key = key.split('/')[-1]\n",
    "    value.to_excel(f\"./issue_data/issue_xlsx/{key}_issue_classify_{date}.xlsx\", index=False, engine='xlsxwriter') # drop the index like RepoName_IssueNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46a0d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "date = datetime(year=2024, month=1, day=1).strftime(\"%Y_%m_%d\")  # 获取当前日期并格式化为年_月_日\n",
    "\n",
    "df.to_excel(f\"./issue_data/issue_xlsx/repo_issue_classify_{date}.xlsx\", index=False, engine='xlsxwriter') # drop the index like RepoName_IssueNumber\n",
    "# df.to_excel(f\"repo_issue_classify.xlsx\", index=False) # drop the index like RepoName_IssueNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2da09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f9bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52441f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc34a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
